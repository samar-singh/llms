{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering agent that is an expert knowledge worker\n",
    "### To be used by employees of Insurellm, an Insurance Tech company\n",
    "### The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain and Chroma and plotly\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5268c8e-e631-467e-bee9-6db3bd88c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import docx \n",
    "import docx2txt \n",
    "import PyPDF2\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    "    CSVLoader\n",
    ")\n",
    "\n",
    "from typing import Optional, Union, Dict, Set\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    "    CSVLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    JSONLoader\n",
    ")\n",
    "\n",
    "class UnsupportedFileTypeError(Exception):\n",
    "    \"\"\"Custom exception for unsupported file types.\"\"\"\n",
    "    pass\n",
    "\n",
    "def get_loader_class(\n",
    "    file_path: Union[str, Path],\n",
    "    strict_mode: bool = False\n",
    ") -> Optional[Union[TextLoader, PyPDFLoader, Docx2txtLoader, CSVLoader, UnstructuredMarkdownLoader, JSONLoader]]:\n",
    "    \"\"\"\n",
    "    Determine the appropriate document loader based on file extension.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Union[str, Path]): Path to the file that needs to be loaded\n",
    "        strict_mode (bool): If True, raises an exception for unsupported file types\n",
    "                          If False, returns None for unsupported types\n",
    "    \n",
    "    Returns:\n",
    "        Optional[Union[...]]: Appropriate loader class for the file type, or None if unsupported\n",
    "        \n",
    "    Raises:\n",
    "        UnsupportedFileTypeError: If strict_mode is True and file type is unsupported\n",
    "        ValueError: If file_path is empty or invalid\n",
    "    \"\"\"\n",
    "    if not file_path:\n",
    "        raise ValueError(\"File path cannot be empty\")\n",
    "    \n",
    "    # Convert to Path object for more robust path handling\n",
    "    path = Path(file_path)\n",
    "    \n",
    "    # Get lowercase extension without the dot\n",
    "    try:\n",
    "        extension = path.suffix.lower().lstrip('.')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid file path format: {str(e)}\")\n",
    "    \n",
    "    # Define skip extensions\n",
    "    SKIP_EXTENSIONS: Set[str] = {\n",
    "        'zip', 'exe', 'bin', 'ppt', 'pptx', \n",
    "        'jpg', 'jpeg', 'png', 'gif', 'bmp',  # Skip binary image formats\n",
    "        'mp3', 'mp4', 'wav', 'avi',          # Skip media files\n",
    "        'db', 'sqlite', 'sqlite3'            # Skip database files\n",
    "    }\n",
    "    \n",
    "    # Define loader mapping\n",
    "    LOADER_MAP: Dict[str, type] = {\n",
    "        'pdf': PyPDFLoader,\n",
    "        'txt': TextLoader,\n",
    "        'text': TextLoader,\n",
    "        'doc': TextLoader,         # Basic text handling for .doc\n",
    "        'docx': Docx2txtLoader,\n",
    "        'csv': CSVLoader,\n",
    "        'md': UnstructuredMarkdownLoader,\n",
    "        'json': JSONLoader\n",
    "    }\n",
    "    \n",
    "    # Check if file type should be skipped\n",
    "    if extension in SKIP_EXTENSIONS:\n",
    "        if strict_mode:\n",
    "            raise UnsupportedFileTypeError(\n",
    "                f\"File type '.{extension}' is not supported for loading\"\n",
    "            )\n",
    "        return None\n",
    "    \n",
    "    # Get appropriate loader or default to TextLoader\n",
    "    loader_class = LOADER_MAP.get(extension)\n",
    "    \n",
    "    if loader_class is None and strict_mode:\n",
    "        raise UnsupportedFileTypeError(\n",
    "            f\"No specific loader found for '.{extension}' files\"\n",
    "        )\n",
    "    \n",
    "    return loader_class or TextLoader  # Default to TextLoader if no specific loader found\n",
    "\n",
    "def get_file_metadata(file_path: Union[str, Path]) -> dict:\n",
    "    \"\"\"\n",
    "    Get metadata about the file to be loaded.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Union[str, Path]): Path to the file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing file metadata\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    return {\n",
    "        'filename': path.name,\n",
    "        'extension': path.suffix.lower().lstrip('.'),\n",
    "        'size_bytes': path.stat().st_size if path.exists() else None,\n",
    "        'absolute_path': str(path.absolute()),\n",
    "        'exists': path.exists(),\n",
    "        'is_file': path.is_file() if path.exists() else None\n",
    "    }\n",
    "\n",
    "def load_documents(base_path: str) -> list:\n",
    "    \"\"\"Load documents from the specified path with appropriate loaders.\"\"\"\n",
    "    documents = []\n",
    "    text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Directory not found: {base_path}\")\n",
    "        return documents\n",
    "        \n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Get appropriate loader\n",
    "                loader_class = get_loader_class(file_path)\n",
    "                \n",
    "                # Skip if no loader is available for this file type\n",
    "                if loader_class is None:\n",
    "                    print(f\"⚠ Skipping unsupported file: {file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Initialize loader with appropriate arguments\n",
    "                if loader_class == TextLoader:\n",
    "                    loader = loader_class(file_path, **text_loader_kwargs)\n",
    "                elif loader_class == CSVLoader:\n",
    "                    loader = loader_class(file_path, encoding='utf-8')\n",
    "                else:\n",
    "                    loader = loader_class(file_path)\n",
    "                \n",
    "                # Load document\n",
    "                docs = loader.load()\n",
    "                \n",
    "                # Add metadata\n",
    "                doc_type = os.path.basename(root)\n",
    "                for doc in docs:\n",
    "                    doc.metadata.update({\n",
    "                        \"doc_type\": doc_type,\n",
    "                        \"source\": file_path,\n",
    "                        \"file_type\": file_path.split('.')[-1],\n",
    "                        \"file_name\": file\n",
    "                    })\n",
    "                    documents.append(doc)\n",
    "                \n",
    "                print(f\"✓ Successfully loaded: {file_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading {file_path}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Usage\n",
    "base_path = \"WILP_ASSIGNMENT_WORK\"\n",
    "documents = load_documents(base_path)\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "\n",
    "# Print document statistics\n",
    "if documents:\n",
    "    file_types = {}\n",
    "    for doc in documents:\n",
    "        file_type = doc.metadata.get('file_type', 'unknown')\n",
    "        file_types[file_type] = file_types.get(file_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nDocument breakdown by file type:\")\n",
    "    for file_type, count in file_types.items():\n",
    "        print(f\"- {file_type}: {count} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065d4b1-80b7-4e15-abd4-60a83e752ea8",
   "metadata": {},
   "source": [
    "# Please note:\n",
    "\n",
    "In the next cell, we split the text into chunks.\n",
    "\n",
    "2 students let me know that the next cell crashed their computer.  \n",
    "They were able to fix it by changing the chunk_size from 1,000 to 2,000 and the chunk_overlap from 200 to 400.  \n",
    "This shouldn't be required; but if it happens to you, please make that change!  \n",
    "(Note that LangChain may give a warning about a chunk being larger than 1,000 - this can be safely ignored).\n",
    "\n",
    "_With much thanks to Steven W and Nir P for this valuable contribution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd06e02f-6d9b-44cc-a43d-e1faa8acc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c54b4b6-06da-463d-bee7-4dd456c2b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: uart_led_lab, WILP Final Dissertation, bitsfinalreportdocs, WILP_ASSIGNMENT_WORK, cpu_risc-master\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7d2a6-ccfa-425b-a1c3-5e55b23bd013",
   "metadata": {},
   "source": [
    "## A sidenote on Embeddings, and \"Auto-Encoding LLMs\"\n",
    "\n",
    "We will be mapping each chunk of text into a Vector that represents the meaning of the text, known as an embedding.\n",
    "\n",
    "OpenAI offers a model to do this, which we will use by calling their API with some LangChain code.\n",
    "\n",
    "This model is an example of an \"Auto-Encoding LLM\" which generates an output given a complete input.\n",
    "It's different to all the other LLMs we've discussed today, which are known as \"Auto-Regressive LLMs\", and generate future tokens based only on past context.\n",
    "\n",
    "Another example of an Auto-Encoding LLMs is BERT from Google. In addition to embedding, Auto-encoding LLMs are often used for classification.\n",
    "\n",
    "### Sidenote\n",
    "\n",
    "In week 8 we will return to RAG and vector embeddings, and we will use an open-source vector encoder so that the data never leaves our computer - that's an important consideration when building enterprise systems and the data needs to remain internal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78998399-ac17-4e28-b15f-0b5f51e6ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "763e51ff-5787-4a56-8176-36b7c5796fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a Chroma Datastore already exists - if so, delete the collection to start from scratch\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "721ed2f8-5c74-4da0-81f3-6ee9cb956574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99fe3a37-480f-4d55-be48-120588d5846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 393 documents\n"
     ]
    }
   ],
   "source": [
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9df0af2-f764-40cf-bbe6-691d04ea6eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 1,536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61e393a0-dd4c-419f-842f-60c1cb3b716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d45462-a818-441c-b010-b85b32bcf618",
   "metadata": {},
   "source": [
    "## Visualizing the Vector Store\n",
    "\n",
    "Let's take a minute to look at the documents and their embedding vectors to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b98adf5e-d464-4bd2-9bdf-bc5b6770263b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m color_mapping\u001b[38;5;241m.\u001b[39mget(doc_type, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'gray' is the default color\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get document types from metadata\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m doc_types \u001b[38;5;241m=\u001b[39m [metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Map to colors with default handling\u001b[39;00m\n\u001b[0;32m     18\u001b[0m colors \u001b[38;5;241m=\u001b[39m [get_color_for_doc_type(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m doc_types]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "def get_color_for_doc_type(doc_type, color_mapping=None):\n",
    "    if color_mapping is None:\n",
    "        # Define default color mapping\n",
    "        color_mapping = {\n",
    "            'WILP_ASSIGNMENT_WORK': 'black',\n",
    "            'cpu_risc-master': 'blue',\n",
    "            'cpu_risc-master_default': 'green',\n",
    "            'uart_led_lab': 'red',\n",
    "            'WILP Final Dissertation': 'orange'\n",
    "        }\n",
    "    # Return a default color if doc_type not in mapping\n",
    "    return color_mapping.get(doc_type, 'gray')  # 'gray' is the default color\n",
    "\n",
    "# Get document types from metadata\n",
    "doc_types = [metadata['doc_type'] for metadata in result['metadatas']]\n",
    "\n",
    "# Map to colors with default handling\n",
    "colors = [get_color_for_doc_type(t) for t in doc_types]\n",
    "\n",
    "# Print unique document types to help debug\n",
    "unique_doc_types = set(doc_types)\n",
    "print(\"Found document types:\", unique_doc_types)\n",
    "\n",
    "# Custom color mapping\n",
    "custom_colors = {\n",
    "    'WILP_ASSIGNMENT_WORK': 'black',\n",
    "    'cpu_risc-master': 'blue',\n",
    "    'cpu_risc-master_default': 'green',\n",
    "    'uart_led_lab': 'red',\n",
    "    'WILP Final Dissertation': 'orange',\n",
    "    'bitsfinalreportdocs': 'purple'  # Add new document type\n",
    "}\n",
    "\n",
    "colors = [get_color_for_doc_type(t, custom_colors) for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "427149d5-e5d8-4abd-bb6f-7ef0333cca21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We humans find it easier to visalize things in 2D!\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Reduce the dimensionality of the vectors to 2D using t-SNE\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# (t-distributed stochastic neighbor embedding)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m reduced_vectors \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mvectors\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create the 2D scatter plot\u001b[39;00m\n\u001b[0;32m      9\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39m[go\u001b[38;5;241m.\u001b[39mScatter(\n\u001b[0;32m     10\u001b[0m     x\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     11\u001b[0m     y\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     hoverinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m )])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3300d111-4769-4b16-9b8b-8721d9fe7e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's try 3D!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m reduced_vectors \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mvectors\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create the 3D scatter plot\u001b[39;00m\n\u001b[0;32m      7\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39m[go\u001b[38;5;241m.\u001b[39mScatter3d(\n\u001b[0;32m      8\u001b[0m     x\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     y\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     hoverinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b3ada26-b4b7-42fc-b943-933c14adf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 4o-mini LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6f7b177-b630-435d-a744-ce74ebce050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HOST in DUT components refers to the VIP (Verification Intellectual Property) used to generate host stimulus following the host protocol. It includes two types of VIPs: the PCIe VIP, which can generate various PCIe GEN3 data traffic over 4 lanes, and the SD VIP, which can generate data and control signals supported by the SD protocol. The HOST is essential for interacting with the DUT by simulating external conditions and stimuli.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you describe the HOST in DUT components in a few sentences\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00058988-de3f-44a5-8530-ee82c7424c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a new conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 4o-mini LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e4aad02-7288-40c4-95f3-d30a56ac658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping in a function - note that history isn't used, as the memory is in the conversation_chain\n",
    "\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "545ecd79-b04c-4986-ae99-eae9cc27c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed09d3d-94d1-4cb4-9db6-0fb3adee3839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
